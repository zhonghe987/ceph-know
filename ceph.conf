; generated by vstart.sh on Tue Jul 12 10:46:50 CST 2016
; CEPH_NUM_MON=1
; CEPH_NUM_OSD=3
; CEPH_NUM_MDS=1
; CEPH_NUM_RGW=1
[global]
        fsid = 85e575a5-0337-4b40-bb48-28173bbc00ff
        osd pg bits = 3
        osd pgp bits = 5  ; (invalid, but ceph should cope!)
        osd crush chooseleaf type = 0
        osd pool default min size = 1
        osd failsafe full ratio = .99
        mon osd reporter subtree level = osd
        mon osd full ratio = .99
        mon data avail warn = 10
        mon data avail crit = 1
        erasure code dir = .libs
        plugin dir = .libs
        osd pool default erasure code profile = plugin=jerasure technique=reed_sol_van k=2 m=1 ruleset-failure-domain=osd
        rgw frontends = fastcgi, civetweb port=8000
        rgw dns name = localhost
        filestore fd cache size = 32
        run dir = /root/ceph/src/out
        enable experimental unrecoverable data corrupting features = *
        lockdep = true
        auth supported = cephx

[client]
        keyring = /root/ceph/src/keyring
        log file = /root/ceph/src/out/$name.$pid.log
        admin socket = /root/ceph/src/out/$name.$pid.asok

[mds]

	log file = /root/ceph/src/out/$name.log
        admin socket = /root/ceph/src/out/$name.asok
	chdir = ""
	pid file = /root/ceph/src/out/$name.pid
        heartbeat file = /root/ceph/src/out/$name.heartbeat


        debug ms = 1
        debug mds = 20
        debug auth = 20
        debug monc = 20
        mds debug scatterstat = true
        mds verify scatter = true
        mds log max segments = 2
        mds debug frag = true
        mds debug auth pins = true
        mds debug subtrees = true
        mds data = /root/ceph/src/dev/mds.$id
        mds root ino uid = 0
        mds root ino gid = 0

[osd]

	log file = /root/ceph/src/out/$name.log
        admin socket = /root/ceph/src/out/$name.asok
	chdir = ""
	pid file = /root/ceph/src/out/$name.pid
        heartbeat file = /root/ceph/src/out/$name.heartbeat

        osd data = /root/ceph/src/dev/osd$id
        osd journal = /root/ceph/src/dev/osd$id/journal
        osd journal size = 100
        osd class tmp = out
        osd class dir = .libs
        osd scrub load threshold = 2000.0
        osd debug op order = true
        filestore wbthrottle xfs ios start flusher = 10
        filestore wbthrottle xfs ios hard limit = 20
        filestore wbthrottle xfs inodes hard limit = 30
        filestore wbthrottle btrfs ios start flusher = 10
        filestore wbthrottle btrfs ios hard limit = 20
        filestore wbthrottle btrfs inodes hard limit = 30
	bluestore fsck on mount = true
	bluestore block create = true
	bluestore block db size = 67108864
	bluestore block db create = true
	bluestore block wal size = 134217728
	bluestore block wal create = true

        debug ms = 1
        debug osd = 25
        debug objecter = 20
        debug monc = 20
        debug journal = 20
        debug filestore = 20
        debug bluestore = 30
        debug bluefs = 20
        debug rocksdb = 10
        debug bdev = 20
        debug rgw = 20
        debug objclass = 20

        osd max object name len = 460
        osd max object namespace len = 64

[mon]
        mon pg warn min per osd = 3
        mon osd allow primary affinity = true
        mon reweight min pgs per osd = 4
        mon osd prime pg temp = true
        crushtool = ./crushtool

	log file = /root/ceph/src/out/$name.log
        admin socket = /root/ceph/src/out/$name.asok
	chdir = ""
	pid file = /root/ceph/src/out/$name.pid
        heartbeat file = /root/ceph/src/out/$name.heartbeat


	debug mon = 20
        debug paxos = 20
        debug auth = 20
        debug ms = 1

        mon cluster log file = /root/ceph/src/out/cluster.mon.$id.log
[global]

[mon.a]
        host = localhost
        mon data = /root/ceph/src/dev/mon.a
        mon addr = 192.168.189.141:6789
[osd.0]
        host = localhost
[osd.1]
        host = localhost
[osd.2]
        host = localhost
[mds.a]
        host = localhost
